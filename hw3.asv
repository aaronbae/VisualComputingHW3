%% Part 0 - Setup
clear all; close all; clc;
addpath('code');
addpath('data');
run('vlfeat/toolbox/vl_setup'); % setup vlfeat library
image_files = get_file_names(); % get image files in data folder

%% Deliverable b: Top Ten Matching features for one pair of images
clc; close all;
images = extract_features( [1,2], image_files, false);
match_results = match_features( [1,2], images);
visualize_features(1, images, match_results, "deliverable_b.jpg", true);
disp("Deliverable b Finished");

%% Deliverable c: 3 Pairs of Epipolar Lines
clc; close all;
index_conversion = [1, 2, 13, 14, 20, 21];
images = extract_features(index_conversion, image_files, false);
match_indices = [1 2; 3 4; 5, 6];
match_results = match_features(match_indices, images);
for i=1:size(match_indices, 1)
    visualize_features(i, images, match_results, "deliverable_c_"+num2str(i)+".jpg", true);
end
disp("Deliverable c Finished");

%% Deliverable d and e: Plot of Camera Orientation and the Horse
clc; close all;
images = extract_features( [1,2], image_files, true);
disp(size(images(1).features));

%% 
clc; close all;
match_results = match_features( [1,2], images);

%% Testing: view the points - shows the sparcity of the features
clc; close all;
visualize_features(1, images, match_results, "deliverable_de.jpg", true);
disp("Deliverable d and e Finished");

%% find parameters of the camera
clc;
plot_feature_3d_points(images, match_results);

%% Function Definition
function plot_feature_3d_points(images, match_results)
    cm = get_correspondence_matrix();
    for i=1:length(match_results)
        match_obj = match_results(1, i);
        img1 = images(match_obj.index1);
        img2 = images(match_obj.index2);
        [K,R1,T1] = get_KRT(match_obj.index1, cm);
        [K,R2,T2] = get_KRT(match_obj.index2, cm);
        
        center1 = inv(K*R1)*(K*R1*T1);
        center2 = inv(K*R2)*(K*R2*T2);
        
        
        f = K(1,1);
        b = abs(sum(T1-T2));
        
        curr_matches = match_obj.matches;
        points_3d = zeros(2,size(curr_matches,2));
        for j=1:size(curr_matches, 2)
            pair = curr_matches(:,j);
            p1 = img1.features(1:2,pair(1));
            p2 = img2.features(1:2,pair(2));
            d = p1 -p2;
            points_3d(:,j) = (f*b./d).';    
        end
    end
end

function [K,R,T]=get_KRT(index, correspondence_matrix)
    c = calc_calibration(index, correspondence_matrix);
    M = c(:,1:3);
    [K, R] = qr(M);
    T = inv(M)*c(:, 4);
end

function file_names = get_file_names()
    files = dir(fullfile('data','*.jpg'));
    for i=1:length(files)
        name = convertCharsToStrings(files(i).name);
        file_names(i) = name;
    end
end

function images=extract_features(array_of_indices, image_files, dense_sift_on_horse)
    FEATURE_REDUCTION_CONSTANT = 5;
    images=[];
    index_check = sum((array_of_indices < 0) + (array_of_indices > 24));
    if index_check ~= 0
        ME = MException('HW3:invalidInputIndex', 'All image indices must be between 0 and 24');
        throw(ME)
    end
    % get all the images
    disp("Feature extraction started...");
    for i=array_of_indices
        modified_index = i*2-1;
        file_name = image_files(modified_index);
        image = getImage(modified_index, image_files);
        if ~dense_sift_on_horse
            [F, D] = vl_sift(image);
        else
            [tempF, tempD] = vl_dsift(image);
            disp("----DSIFT for image "+num2str(i)+" ended");
            filter = zeros(1, size(tempF, 2));
            mask_index = i*2;
            mask = getImage(mask_index, image_files);
            for j=1:size(tempF, 2)
                p = floor(tempF(1:2, j));
                %if mask(p(2), p(1))
                if mask(p(2), p(1)) && mod(p(1), FEATURE_REDUCTION_CONSTANT) == 0 && mod(p(2), FEATURE_REDUCTION_CONSTANT) == 0
                    filter(j) = 1;
                end
            end
            F = tempF(:, filter==1);
            D = tempD(:, filter==1);
        end
        images = [images struct('index', i, 'file_name', file_name, 'image', image, 'features', F, 'descriptors', D)];
        disp("----Finished processing image "+num2str(i));
    end
end

function match_results=match_features(indices, images)
    LINE_THRESHOLD_CONSTANT = 10;
    disp("Feature matching started...");
    % calculate sift for every adjacent pairs
    match_results = [];
    correspondence_matrix = get_correspondence_matrix();
    for i=1:size(indices, 1)
        index1 = indices(i,1);
        index2 = indices(i,2);
        obj1 = images(index1);
        obj2 = images(index2);
        match_obj = struct('index1', index1, 'index2', index2);
        disp("----Started initial matching of features for images "+num2str(obj1.index)+ " and "+num2str(obj2.index));
        [tempM, tempS] = vl_ubcmatch(obj1.descriptors, obj2.descriptors);
        disp("----Finished initial matching of features for images "+num2str(obj1.index)+ " and "+num2str(obj2.index));
        
        % Save epipolar geometry info
        [fundamental_matrix, e1, e2] = get_fundamental_matrix(obj1.index, obj2.index, correspondence_matrix);
        match_obj.fundamental_matrix = fundamental_matrix;
        match_obj.e1 = e1;
        match_obj.e2 = e2;
        
        % filter features by epipolar geometry
        img1_points = obj1.features;
        img2_points = obj2.features;
        img1_points = vertcat(img1_points(1:2,:),ones(1,size(img1_points, 2))).';
        img2_points = vertcat(img2_points(1:2,:),ones(1,size(img2_points, 2))).';
        filter = zeros(1, size(tempM, 2));
        disp("----Epipolar filtering began for images "+num2str(obj1.index)+ " and "+num2str(obj2.index));
        for j=1:size(tempM, 2)
            % calculate the points on both images
            p1 = img1_points(tempM(1,j), :);
            p1 = p1./p1(3);
            p2 = img2_points(tempM(2,j), :);
            p2 = p2./p2(3);
            
            % lines that are created by the fundamental matrix
            v = fundamental_matrix*p1.';
            m = -v(1)/v(2);
            b = -v(3)/v(2);
            if abs(p2(2) - m*p2(1)-b) < LINE_THRESHOLD_CONSTANT
                filter(j) = 1;
            end
        end
        match_obj.matches = tempM(:,filter==1);
        match_obj.scores = tempS(:,filter==1);
        
        match_results = [match_results match_obj];
        disp("----Finished matching for image "+num2str(obj1.index)+" and "+num2str(obj2.index));
    end        
end

function matrix=get_correspondence_matrix()
    % Summary:
    %   - returns the correspondence matrix that we pre-calcualted by hand
    %   - matrix has 20 rows. These are the 20 possible points in the image
    %   world.
    %   - matrix has 24 columns. These are the 12 different images with
    %   alternating X and Y values for each image.
    % Returns:
    %   - matrix: 20 x 24 matrix
    matrix = csvread('correspondence_points.csv');
    matrix = matrix(:, 1:end-1);
    matrix(matrix==0) = NaN;
end

function [F, e1, e2]=get_fundamental_matrix(image_index_1, image_index_2, correspondence_matrix)
    [points_3d, img1_points_2d]=get_correspondence_points(image_index_1, correspondence_matrix, false);
    [points_3d, img2_points_2d]=get_correspondence_points(image_index_2, correspondence_matrix, false);
    non_nan_index = sum(~isnan(img1_points_2d) + ~isnan(img2_points_2d),2) == 4;
    img1_points_2d = img1_points_2d(non_nan_index,:);
    img1_points_2d = horzcat(img1_points_2d, ones(size(img1_points_2d, 1), 1)).';
    img2_points_2d = img2_points_2d(non_nan_index,:);
    img2_points_2d = horzcat(img2_points_2d, ones(size(img2_points_2d, 1), 1)).';
    [F, e1, e2] = fundmatrix(img1_points_2d, img2_points_2d);
end

function [points_3d, points_2d]=get_correspondence_points(image_index, correspondence_matrix, process_nan)
    points_3d = [
        0 0 19; % Blue Top
        64 0 19;
        64 64 19;
        0 64 19;
        0 0 29; % Red Top
        64 0 29;
        64 64 29;
        0 64 29;
        16 16 48; % Center Green Top
        48 16 48;
        48 48 48;
        16 48 48;
        0 48 48; % Corner Greeen Top
        32 48 48;
        32 80 48;
        0 80 48;
        0 48 67; % Yellow Top
        32 48 67;
        32 80 67;
        0 80 67];
    X = correspondence_matrix(:,image_index*2-1);
    Y = correspondence_matrix(:,image_index*2);
    if process_nan
        non_nan_index = ~isnan(X); % if X is Non-NaN, Y is Non-Nan
        X = X(non_nan_index);
        Y = Y(non_nan_index);
        points_3d = points_3d(non_nan_index, :);
    end
    points_2d = horzcat(X,Y);
    
    if process_nan
        % use only 8 points
        threshold = min(size(points_3d,1), 8);
        points_3d = points_3d(1:threshold, :);
        points_2d = points_2d(1:threshold, :);
    end
end

function visualize_features(match_index, sift_results, match_results, title, draw_epipolar_lines)
    obj1 = sift_results(match_results(match_index).index1);
    obj2 = sift_results(match_results(match_index).index2);
    features1 = obj1.features;
    features2 = obj2.features;
    matches = match_results(match_index).matches;
    sz = 40;

    % graph feature points
    figure();
    subplot(1, 2, 1);
    imshow(obj1.image)
    hold on
    if size(matches,2) > 0
        scatter(features1(1,matches(1,:)), features1(2,matches(1,:)), sz, 'r', 'filled')
    end
        
    subplot(1, 2, 2);
    imshow(obj2.image)
    hold on
    if size(matches,2) > 0
        scatter(features2(1,matches(2,:)), features2(2,matches(2,:)), sz, 'r', 'filled')
    end
    
    if draw_epipolar_lines
        domain = linspace(0, size(obj2.image,2));
        fundmat = match_results(match_index).fundamental_matrix;
        for i=1:size(matches, 2)
            % feature points in image 1
            p = [features1(1:2, matches(1,i)); 1];
            p = p ./ p(3);
            line = fundmat * p;
            slope = -line(1) / line(2);
            offset = -line(3) / line(2);
            range = slope*domain + offset;
            plot(domain, range,'b','LineWidth',2);
        end
    end
    ha=get(gcf,'children');
    set(gcf, 'position', [80 180 1424 534]);
    set(ha(1),'position',[0 0 .5 1]);
    set(ha(2),'position',[.5 0 .5 1]);
    saveas(gcf, "output/"+title);
end

function img = getImage(index, image_files)
    % Summary:
    %   - retrieves the given image by index
    %   - odds are images and evens are masks
    % Parameters:
    %   - index: a number 
    %   - image_files: the list of file names in the '/data/' folder
    img = im2single( rgb2gray(imread( convertStringsToChars(image_files(index)) ) ) );
end

function c=calc_calibration(image_index, correspondence_matrix)
    [points_3d, points_2d] = get_correspondence_points(image_index, correspondence_matrix, true);
    A = [];
    B = [];
    for i=1:size(points_3d,1)
        p_3d = points_3d(i,:);
        x = p_3d(1);
        y = p_3d(2);
        z = p_3d(3);
        w = 1;
        p_2d = points_2d(i,:);
        u = p_2d(1);
        v = p_2d(2);
        row1 = [-x -y -z -w  0  0  0  0 u*x u*y u*z];
        row2 = [ 0  0  0  0 -z -y -z -w v*x v*y v*z];
        A = [A; row1; row2];
        B = [B; -u; -v];
    end
    warning('off','all');
    c = linsolve(A, B);
    warning('on','all');
    c = [c; 1];
    c = reshape(c, [4,3]).';
end